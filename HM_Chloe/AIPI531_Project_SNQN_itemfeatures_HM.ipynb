{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hj151mids/aipi_531_group_c/blob/snqn_item/AIPI531_Project_SNQN_itemfeatures_retailrocket.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HM data with item features implementation"
      ],
      "metadata": {
        "id": "WAJkLMhsJeNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps to run the Source code(python scripts) for the final project"
      ],
      "metadata": {
        "id": "txouUAVRcoJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run the repositories, you need to upgrade the code to TensorFlow 2. Follow the steps given below to run the python scripts\n",
        "\n",
        "1) Mount you google drive with all the scripts and point to the folder containing the source code"
      ],
      "metadata": {
        "id": "AqJZBRxZcGCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IYlNxGemvPn",
        "outputId": "5043551a-c476-4e3d-f026-ad9b534b87c8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH_p3AaD6VII",
        "outputId": "907ff15f-5977-4603-dbff-575aaaab8f8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/aipi/Final Project/aipi_531_group_c/HM\n",
            " 00_data_preprocessing.ipynb  'Icon'$'\\r'\t     SNQN_item.py   utility.py\n",
            " 01_replay_buffer.py\t       NextItNetModules.py   SNQN.py\n",
            " 01_split_data.py\t       pop.py\t\t     SNQN_v1.py\n",
            " Data\t\t\t       __pycache__\t     test.py\n"
          ]
        }
      ],
      "source": [
        "PROJ_DIR = '/content/drive/MyDrive/Colab Notebooks/aipi/Final Project/aipi_531_group_c/HM'\n",
        "# change current directory after mounting\n",
        "%cd $PROJ_DIR\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pandas trfl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D48QnNqM88n5",
        "outputId": "fb170a9b-5cb3-4621-8909-d31125f236ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: trfl in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Then just provide appropriate arguments and select the model you want to train on and execute "
      ],
      "metadata": {
        "id": "dZyD9tIGgmPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python SNQN_v1.py --model=GRU --epoch=1"
      ],
      "metadata": {
        "id": "kXfoai0HzuuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36219058-1d66-4ab0-bbd0-873020ad9342"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-04 05:04:30.702703: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-04 05:04:35.042657: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/drive/MyDrive/Colab Notebooks/aipi/Final Project/aipi_531_group_c/HM/SNQN_v1.py:124: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Colab Notebooks/aipi/Final Project/aipi_531_group_c/HM/SNQN_v1.py:123: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:584: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:598: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "/content/drive/MyDrive/Colab Notebooks/aipi/Final Project/aipi_531_group_c/HM/SNQN_v1.py:295: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(\n",
            "/content/drive/MyDrive/Colab Notebooks/aipi/Final Project/aipi_531_group_c/HM/SNQN_v1.py:299: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output_phi = tf.compat.v1.layers.dense(\n",
            "/content/drive/MyDrive/Colab Notebooks/aipi/Final Project/aipi_531_group_c/HM/SNQN_v1.py:303: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.feature_embeddings = tf.compat.v1.layers.dense(\n",
            "2023-05-04 05:04:55.909793: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 13999, total purchase:92359\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 18.600000\n",
            "clicks hr ndcg @ 5 : 0.002000, 0.000861\n",
            "purchase hr and ndcg @5 : 0.000141, 0.000076\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 48.200000\n",
            "clicks hr ndcg @ 10 : 0.004000, 0.001574\n",
            "purchase hr and ndcg @10 : 0.000401, 0.000162\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 68.200000\n",
            "clicks hr ndcg @ 15 : 0.004000, 0.001574\n",
            "purchase hr and ndcg @15 : 0.000617, 0.000219\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 92.200000\n",
            "clicks hr ndcg @ 20 : 0.004000, 0.001574\n",
            "purchase hr and ndcg @20 : 0.000877, 0.000280\n",
            "#############################################################\n",
            "the loss in 200th batch is: 9.868434\n",
            "the loss in 400th batch is: 9.708950\n",
            "the loss in 600th batch is: 9.291768\n",
            "the loss in 800th batch is: 9.310738\n",
            "the loss in 1000th batch is: 8.960316\n",
            "the loss in 1200th batch is: 8.518105\n",
            "the loss in 1400th batch is: 8.510860\n",
            "the loss in 1600th batch is: 8.527443\n",
            "the loss in 1800th batch is: 8.569235\n",
            "the loss in 2000th batch is: 8.514746\n",
            "the loss in 2200th batch is: 8.040725\n",
            "the loss in 2400th batch is: 8.182516\n",
            "the loss in 2600th batch is: 8.116556\n",
            "the loss in 2800th batch is: 7.760799\n",
            "the loss in 3000th batch is: 7.975232\n"
          ]
        }
      ]
    }
  ]
}