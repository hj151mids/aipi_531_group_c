{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hj151mids/aipi_531_group_c/blob/snqn_item/AIPI531_Project_SNQN_itemfeatures_retailrocket.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HM data without item feature implementaion"
      ],
      "metadata": {
        "id": "f1e1T_sBF9Eo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps to run the Source code(python scripts) for the final project"
      ],
      "metadata": {
        "id": "txouUAVRcoJn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To run the repositories, you need to upgrade the code to TensorFlow 2. Follow the steps given below to run the python scripts\n",
        "\n",
        "1) Mount you google drive with all the scripts and point to the folder containing the source code"
      ],
      "metadata": {
        "id": "AqJZBRxZcGCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IYlNxGemvPn",
        "outputId": "a870388d-e3ca-42e9-fa63-a96133d08bbd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH_p3AaD6VII",
        "outputId": "8e508a22-25ca-4f4b-98c2-438fd1f44900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/aipi/Final Project/aipi_531_group_c/HM\n",
            " 00_data_preprocessing.ipynb  'Icon'$'\\r'\t     SNQN_item.py   utility.py\n",
            " 01_replay_buffer.py\t       NextItNetModules.py   SNQN.py\n",
            " 01_split_data.py\t       pop.py\t\t     SNQN_v1.py\n",
            " Data\t\t\t       __pycache__\t     test.py\n"
          ]
        }
      ],
      "source": [
        "PROJ_DIR = '/content/drive/MyDrive/Colab Notebooks/aipi/Final Project/aipi_531_group_c/HM'\n",
        "# change current directory after mounting\n",
        "%cd $PROJ_DIR\n",
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pandas trfl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D48QnNqM88n5",
        "outputId": "bd7d9a53-5c4a-489b-8462-dfac318a2e39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from trfl) (0.1.8)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from trfl) (1.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from trfl) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from trfl) (1.14.1)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Then just provide appropriate arguments and select the model you want to train on and execute "
      ],
      "metadata": {
        "id": "dZyD9tIGgmPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python SNQN.py --model=GRU --epoch=1"
      ],
      "metadata": {
        "id": "kXfoai0HzuuH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cd7432e-9314-425c-d3d0-f720e7950b02"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-04 05:37:47.411218: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-04 05:37:48.967071: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/drive/MyDrive/Colab Notebooks/aipi/Final Project/aipi_531_group_c/HM/SNQN.py:105: UserWarning: `tf.nn.rnn_cell.GRUCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.GRUCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  tf.compat.v1.nn.rnn_cell.GRUCell(self.hidden_size),\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/Colab Notebooks/aipi/Final Project/aipi_531_group_c/HM/SNQN.py:104: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:584: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:598: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "/content/drive/MyDrive/Colab Notebooks/aipi/Final Project/aipi_531_group_c/HM/SNQN.py:232: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "/content/drive/MyDrive/Colab Notebooks/aipi/Final Project/aipi_531_group_c/HM/SNQN.py:235: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,\n",
            "2023-05-04 05:38:00.335731: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "#############################################################\n",
            "total clicks: 13999, total purchase:92359\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 21.000000\n",
            "clicks hr ndcg @ 5 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @5 : 0.000227, 0.000135\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 10: 34.000000\n",
            "clicks hr ndcg @ 10 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @10 : 0.000368, 0.000179\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 15: 56.000000\n",
            "clicks hr ndcg @ 15 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @15 : 0.000606, 0.000242\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 20: 76.000000\n",
            "clicks hr ndcg @ 20 : 0.000000, 0.000000\n",
            "purchase hr and ndcg @20 : 0.000823, 0.000293\n",
            "#############################################################\n",
            "the loss in 200th batch is: 9.913169\n",
            "the loss in 400th batch is: 9.428541\n",
            "the loss in 600th batch is: 9.434555\n",
            "the loss in 800th batch is: 9.082426\n",
            "the loss in 1000th batch is: 8.875235\n",
            "the loss in 1200th batch is: 8.832888\n",
            "the loss in 1400th batch is: 8.927063\n",
            "the loss in 1600th batch is: 8.588917\n",
            "the loss in 1800th batch is: 8.495147\n",
            "the loss in 2000th batch is: 8.630308\n",
            "the loss in 2200th batch is: 8.040902\n",
            "the loss in 2400th batch is: 8.626831\n",
            "the loss in 2600th batch is: 8.197166\n",
            "the loss in 2800th batch is: 8.209708\n",
            "the loss in 3000th batch is: 8.025248\n"
          ]
        }
      ]
    }
  ]
}